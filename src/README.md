# æ•°æ®é›†ç‰¹å¾æå–å·¥å…·åŒ… (src)

## ğŸ“– æ¦‚è¿°

è¿™æ˜¯ä¸€ä¸ªå…¨é¢çš„æ•°æ®é›†è´¨é‡åˆ†æå·¥å…·åŒ…ï¼Œæ”¯æŒä»å¤šä¸ªç»´åº¦æå–æ•°æ®é›†ç‰¹å¾ï¼ŒåŒ…æ‹¬åŸºç¡€ç‰¹å¾ã€é™æ€ç‰¹å¾å’ŒåŠ¨æ€ç‰¹å¾ã€‚å·¥å…·åŒ…é‡‡ç”¨æ¨¡å—åŒ–è®¾è®¡ï¼Œæ”¯æŒå¤šå¡å¹¶è¡Œå’Œæ‰¹é‡å¤„ç†ï¼Œå¤§å¹…æå‡ç‰¹å¾æå–æ•ˆç‡ã€‚

## ğŸ—ï¸ æ¶æ„è®¾è®¡

```
src/
â”œâ”€â”€ __init__.py                 # åŒ…å…¥å£ï¼Œå¯¼å‡ºä¸»è¦æ¥å£
â”œâ”€â”€ data_parsers.py            # æ•°æ®è§£ææ¨¡å—
â”œâ”€â”€ static_features.py         # é™æ€ç‰¹å¾æå–æ¨¡å—
â”œâ”€â”€ dynamic_probes.py          # åŠ¨æ€æ¨¡å‹æ¢é’ˆæ¨¡å—
â”œâ”€â”€ feature_dispatcher.py      # ç‰¹å¾æ€»è°ƒåº¦æ¨¡å—
â”œâ”€â”€ optimized_feature_extractor.py  # ä¼˜åŒ–ç‰¹å¾æå–å™¨
â””â”€â”€ README.md                  # æœ¬æ–‡ä»¶
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. åŸºç¡€ä½¿ç”¨

```python
from src import extract_all_features, HyperParams

# åˆ›å»ºè¶…å‚æ•°
hyperparams = HyperParams(
    learning_rate=1e-4,
    lora_r=8,
    lora_alpha=16
)

# æå–æ‰€æœ‰ç‰¹å¾
features = extract_all_features(
    dataset=your_dataset,
    hyperparams=hyperparams,
    base_model_name="your_model_path",
    static_sample_size=100,
    dynamic_probe_steps=100,
    dynamic_sample_size=50,
    save_to_csv=True,
    csv_filename="features.csv"
)
```

### 2. ä¼˜åŒ–ç‰ˆæœ¬ä½¿ç”¨

```python
from src.optimized_feature_extractor import OptimizedFeatureExtractor

# åˆå§‹åŒ–ä¼˜åŒ–ç‰¹å¾æå–å™¨
extractor = OptimizedFeatureExtractor(
    base_model_name="your_model_path",
    batch_size=8,      # æ‰¹å¤„ç†å¤§å°
    num_gpus=None      # è‡ªåŠ¨æ£€æµ‹GPUæ•°é‡
)

# æå–ç‰¹å¾
features = extractor.extract_all_features_optimized(
    dataset=your_dataset,
    hyperparams=hyperparams,
    static_sample_size=100,
    dynamic_probe_steps=100,
    dynamic_sample_size=50,
    save_to_csv=True
)

# æ¸…ç†èµ„æº
extractor.cleanup()
```

## ğŸ“Š ç‰¹å¾ç±»å‹

### 1. åŸºç¡€ç‰¹å¾ (5ä¸ª)
- `learning_rate`: å­¦ä¹ ç‡
- `lora_r`: LoRA rank
- `lora_alpha`: LoRA alpha
- `dataset_size`: æ•°æ®é›†å¤§å°
- `initial_loss`: åˆå§‹æŸå¤±

### 2. æ–‡æœ¬ç»Ÿè®¡ç‰¹å¾ (10ä¸ª)
- `avg_input_length`: å¹³å‡è¾“å…¥é•¿åº¦
- `avg_output_length`: å¹³å‡è¾“å‡ºé•¿åº¦
- `io_length_ratio`: è¾“å…¥è¾“å‡ºé•¿åº¦æ¯”
- `input_length_std`: è¾“å…¥é•¿åº¦æ ‡å‡†å·®
- `output_length_std`: è¾“å‡ºé•¿åº¦æ ‡å‡†å·®
- `input_ttr`: è¾“å…¥TTR (ç±»ç¬¦/å½¢ç¬¦æ¯”)
- `output_ttr`: è¾“å‡ºTTR
- `output_ngram_repetition`: è¾“å‡ºn-gramé‡å¤ç‡
- `approximate_duplicates`: è¿‘ä¼¼é‡å¤æ ·æœ¬æ¯”ä¾‹
- `vocab_complexity`: è¯æ±‡å¤æ‚åº¦

### 3. è¯­ä¹‰ç‰¹å¾ (3ä¸ª)
- `semantic_diversity`: è¯­ä¹‰å¤šæ ·æ€§
- `io_similarity`: è¾“å…¥è¾“å‡ºç›¸ä¼¼åº¦
- `semantic_consistency`: è¯­ä¹‰ä¸€è‡´æ€§

### 4. å›°æƒ‘åº¦ç‰¹å¾ (5ä¸ª)
- `reference_perplexity`: å‚è€ƒæ¨¡å‹å›°æƒ‘åº¦
- `base_model_perplexity`: åŸºç¡€æ¨¡å‹å›°æƒ‘åº¦
- `perplexity_change_rate`: å›°æƒ‘åº¦å˜åŒ–ç‡
- `reference_perplexity_std`: å‚è€ƒå›°æƒ‘åº¦æ ‡å‡†å·®
- `base_perplexity_std`: åŸºç¡€å›°æƒ‘åº¦æ ‡å‡†å·®

### 5. åŠ¨æ€ç‰¹å¾ (3ä¸ª)
- `loss_decay_rate`: æŸå¤±ä¸‹é™ç‡
- `avg_grad_norm`: å¹³å‡æ¢¯åº¦èŒƒæ•°
- `gradient_consistency`: æ¢¯åº¦ä¸€è‡´æ€§

## ğŸ”§ æ¨¡å—è¯¦è§£

### data_parsers.py
**åŠŸèƒ½**: æ•°æ®è§£æå’Œæ ¼å¼åŒ–
- `HyperParams`: è¶…å‚æ•°é…ç½®ç±»
- `DatasetAnalyzer`: æ•°æ®é›†åˆ†æå™¨åŸºç±»
- æ”¯æŒå¤šç§æ•°æ®æ ¼å¼ (Qwen2.5æ ¼å¼ã€ç®€å•QAå¯¹æ ¼å¼)
- æä¾›åŸºç¡€æ•°æ®è§£æåŠŸèƒ½

### static_features.py
**åŠŸèƒ½**: é™æ€ç‰¹å¾æå–
- `StaticFeatureExtractor`: é™æ€ç‰¹å¾æå–å™¨
- ç»§æ‰¿è‡ª `DatasetAnalyzer`
- æå–ä¸éœ€è¦æ¨¡å‹è®­ç»ƒçš„é™æ€ç‰¹å¾
- åŒ…æ‹¬æ–‡æœ¬ç»Ÿè®¡ã€è¯­ä¹‰ç‰¹å¾ã€å›°æƒ‘åº¦ç‰¹å¾

### dynamic_probes.py
**åŠŸèƒ½**: åŠ¨æ€æ¨¡å‹æ¢é’ˆ
- `DynamicProbeAnalyzer`: åŠ¨æ€æ¢é’ˆåˆ†æå™¨
- åŸºäºæ¨¡å‹å¾®è°ƒçš„åŠ¨æ€ç‰¹å¾åˆ†æ
- è®¡ç®—æŸå¤±ä¸‹é™ç‡ã€æ¢¯åº¦èŒƒæ•°ã€æ¢¯åº¦ä¸€è‡´æ€§
- éœ€è¦æ¨¡å‹è®­ç»ƒï¼Œè®¡ç®—æˆæœ¬è¾ƒé«˜

### feature_dispatcher.py
**åŠŸèƒ½**: ç‰¹å¾æ€»è°ƒåº¦
- `extract_all_features()`: æå–æ‰€æœ‰ç‰¹å¾çš„ä¸»å‡½æ•°
- `save_features_to_csv()`: ä¿å­˜ç‰¹å¾åˆ°CSVæ–‡ä»¶
- ç»Ÿä¸€è°ƒåº¦æ‰€æœ‰æ¨¡å—ç‰¹å¾æå–
- ä¼˜åŒ–ç­–ç•¥ï¼šå°†åŠ¨æ€æ¢é’ˆæ”¾åœ¨æœ€åï¼Œåªä½¿ç”¨ä¸€ä¸ªæ¨¡å‹å®ä¾‹

### optimized_feature_extractor.py
**åŠŸèƒ½**: ä¼˜åŒ–ç‰¹å¾æå–å™¨
- `OptimizedFeatureExtractor`: ä¼˜åŒ–ç‰¹å¾æå–å™¨
- æ”¯æŒå¤šå¡å¹¶è¡Œå’Œæ‰¹é‡å¤„ç†
- ä¸»è¿›ç¨‹ä¸²è¡Œè°ƒåº¦å¤šå¡ï¼Œé¿å…å¹¶å‘é—®é¢˜
- å¤§å¹…æå‡ç‰¹å¾æå–é€Ÿåº¦

## âš¡ æ€§èƒ½ä¼˜åŒ–

### 1. å¤šå¡å¹¶è¡Œ
- è‡ªåŠ¨æ£€æµ‹å¯ç”¨GPUæ•°é‡
- æ¯ä¸ªGPUç‹¬ç«‹åŠ è½½æ¨¡å‹å®ä¾‹
- æ‰¹æ¬¡è½®æµåˆ†é…åˆ°ä¸åŒGPUä¸Šå¤„ç†

### 2. æ‰¹é‡å¤„ç†
- æ”¯æŒå¯é…ç½®çš„æ‰¹å¤„ç†å¤§å°
- å‡å°‘æ¨¡å‹è°ƒç”¨æ¬¡æ•°ï¼Œæå‡æ•ˆç‡
- æ ¹æ®æ˜¾å­˜æƒ…å†µè°ƒæ•´batch_size

### 3. æ˜¾å­˜ä¼˜åŒ–
- ä½¿ç”¨float16å‡å°‘æ˜¾å­˜ä½¿ç”¨
- åŠæ—¶æ¸…ç†æ˜¾å­˜
- æ¨¡å‹å…±äº«ï¼Œé¿å…é‡å¤åŠ è½½

## ğŸ“ ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹1: åŸºç¡€ç‰¹å¾æå–
```python
from src import extract_all_features, HyperParams

hyperparams = HyperParams(learning_rate=1e-4, lora_r=8, lora_alpha=16)
features = extract_all_features(
    dataset=dataset,
    hyperparams=hyperparams,
    base_model_name="Qwen2.5-7B-Instruct",
    static_sample_size=50,
    dynamic_probe_steps=50,
    dynamic_sample_size=20
)
```

### ç¤ºä¾‹2: ä¼˜åŒ–ç‰¹å¾æå–
```python
from src.optimized_feature_extractor import OptimizedFeatureExtractor

extractor = OptimizedFeatureExtractor(
    base_model_name="Qwen2.5-7B-Instruct",
    batch_size=4,
    num_gpus=None
)

features = extractor.extract_all_features_optimized(
    dataset=dataset,
    hyperparams=hyperparams,
    static_sample_size=50,
    dynamic_probe_steps=50,
    dynamic_sample_size=20
)
```

### ç¤ºä¾‹3: ä¿å­˜ç‰¹å¾åˆ°CSV
```python
features = extract_all_features(
    dataset=dataset,
    hyperparams=hyperparams,
    base_model_name="Qwen2.5-7B-Instruct",
    save_to_csv=True,
    csv_filename="dataset_features.csv"
)
```

## ğŸ” å‚æ•°è°ƒä¼˜å»ºè®®

### 1. é™æ€ç‰¹å¾å‚æ•°
- `static_sample_size`: å»ºè®®100-500ï¼Œæ ¹æ®æ•°æ®é›†å¤§å°è°ƒæ•´
- æ ·æœ¬æ•°è¶Šå¤šï¼Œç‰¹å¾è¶Šå‡†ç¡®ï¼Œä½†è®¡ç®—æ—¶é—´è¶Šé•¿

### 2. åŠ¨æ€ç‰¹å¾å‚æ•°
- `dynamic_probe_steps`: å»ºè®®50-200æ­¥
- `dynamic_sample_size`: å»ºè®®20-100ä¸ªæ ·æœ¬
- æ­¥æ•°å’Œæ ·æœ¬æ•°è¶Šå¤šï¼ŒåŠ¨æ€ç‰¹å¾è¶Šç¨³å®š

### 3. ä¼˜åŒ–å‚æ•°
- `batch_size`: æ ¹æ®æ˜¾å­˜å¤§å°è°ƒæ•´ï¼Œå»ºè®®4-16
- `num_gpus`: è‡ªåŠ¨æ£€æµ‹ï¼Œæˆ–æ‰‹åŠ¨æŒ‡å®š

### 4. è¶…å‚æ•°å»ºè®®
```python
# æ ‡å‡†é…ç½®
HyperParams(learning_rate=1e-4, lora_r=8, lora_alpha=16)

# é«˜ç²¾åº¦é…ç½®
HyperParams(learning_rate=5e-5, lora_r=16, lora_alpha=32)

# å¿«é€Ÿé…ç½®
HyperParams(learning_rate=5e-4, lora_r=4, lora_alpha=8)
```

## ğŸ› å¸¸è§é—®é¢˜

### 1. æ˜¾å­˜ä¸è¶³
**è§£å†³æ–¹æ¡ˆ**:
- å‡å°‘ `batch_size`
- å‡å°‘ `static_sample_size` å’Œ `dynamic_sample_size`
- ä½¿ç”¨ `torch.float16`

### 2. åŠ¨æ€ç‰¹å¾ä¸º0
**å¯èƒ½åŸå› **:
- åŠ¨æ€æ¢é’ˆæ­¥æ•°å¤ªå°‘
- å­¦ä¹ ç‡è®¾ç½®ä¸å½“
- æ ·æœ¬æ•°é‡ä¸è¶³
- LoRAé…ç½®é—®é¢˜

**è§£å†³æ–¹æ¡ˆ**:
- å¢åŠ  `dynamic_probe_steps` åˆ°100-200
- è°ƒæ•´å­¦ä¹ ç‡åˆ°1e-4æˆ–1e-5
- å¢åŠ æ ·æœ¬æ•°é‡åˆ°20-50

### 3. å¹¶å‘é”™è¯¯ (Already borrowed)
**è§£å†³æ–¹æ¡ˆ**:
- ä½¿ç”¨ `OptimizedFeatureExtractor` è€Œä¸æ˜¯å¤šçº¿ç¨‹
- ç¡®ä¿ä½¿ç”¨ä¸»è¿›ç¨‹ä¸²è¡Œè°ƒåº¦å¤šå¡

## ğŸ“ˆ æ€§èƒ½å¯¹æ¯”

| æ–¹æ³• | é€Ÿåº¦ | ç¨³å®šæ€§ | æ˜¾å­˜ä½¿ç”¨ | é€‚ç”¨åœºæ™¯ |
|------|------|--------|----------|----------|
| åŸºç¡€æ–¹æ³• | ä¸­ç­‰ | é«˜ | ä½ | å°æ•°æ®é›†ï¼Œå•å¡ |
| ä¼˜åŒ–æ–¹æ³• | é«˜ | é«˜ | ä¸­ç­‰ | å¤§æ•°æ®é›†ï¼Œå¤šå¡ |

## ğŸ”„ ç‰ˆæœ¬å†å²

- **v1.0.0**: åˆå§‹ç‰ˆæœ¬ï¼ŒåŒ…å«åŸºç¡€ç‰¹å¾æå–åŠŸèƒ½
- **v1.1.0**: æ·»åŠ ä¼˜åŒ–ç‰¹å¾æå–å™¨ï¼Œæ”¯æŒå¤šå¡å¹¶è¡Œ
- **v1.2.0**: ä¿®å¤å¹¶å‘é—®é¢˜ï¼Œä¼˜åŒ–æ˜¾å­˜ä½¿ç”¨

## ğŸ“ æŠ€æœ¯æ”¯æŒ

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·æŸ¥çœ‹ï¼š
1. æµ‹è¯•è„šæœ¬: `test_optimized_feature_extraction.py`
2. æ€§èƒ½å¯¹æ¯”: `performance_comparison.py`
3. åŠ¨æ€ç‰¹å¾æµ‹è¯•: `test_dynamic_features.py`

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ã€‚ 